{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m      8\u001b[0m \u001b[39m#import matplotlib\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPython \u001b[39m\u001b[39m{\u001b[39;00msys\u001b[39m.\u001b[39mversion\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#import matplotlib\n",
    "\n",
    "\n",
    "print(f\"Python {sys.version}\")\n",
    "print()\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Scikit-Learn: {sk.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "#print(f\"Matplotlib: {matplotlib.__version__}\")\n",
    "print()\n",
    "print(\"GPU is \", \"available\" if tf.config.list_physical_devices('GPU') else \"not available\")\n",
    "print(f\"CUDA: {tf.test.is_built_with_cuda()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR='C:/Users/ultimate_beast/Downloads/CIFAR-10-images-master/CIFAR-10-images-master/train'\n",
    "CATEGORIES=os.listdir(TRAIN_DIR)\n",
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA=[]\n",
    "for c in CATEGORIES:\n",
    "    path=os.path.join(TRAIN_DIR,c)\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        img_arr=cv2.imread(os.path.join(path,img))\n",
    "        class_num=CATEGORIES.index(c)\n",
    "        TRAIN_DATA.append((img.arr,class_num))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andom.shuffle(TRAIN_DATA)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(50):\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.imshow(TRAIN_DATA[i][0])\n",
    "    plt.xlabel(CATEGORIES[TRAIN_DATA[i][1]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i==50:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = TRAIN_DATA[:1000]\n",
    "f1 = TRAIN_DATA[1000:2000]\n",
    "f2 = TRAIN_DATA[2000:3000]\n",
    "f3 = TRAIN_DATA[3000:4000]\n",
    "f4 = TRAIN_DATA[4000:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "midpoint_l1_accuracies = []\n",
    "midpoint_l2_accuracies = []\n",
    "\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        train = f1+f2+f3+f4\n",
    "        validation = f0\n",
    "    elif i==1:\n",
    "        train = f0+f2+f3+f4\n",
    "        validation = f1\n",
    "    elif i==2:\n",
    "        train = f0+f1+f3+f4\n",
    "        validation = f2\n",
    "    elif i==3:\n",
    "        train = f0+f1+f2+f4\n",
    "        validation = f3\n",
    "    elif i==4:\n",
    "        train = f0+f1+f2+f3\n",
    "        validation = f4\n",
    "\n",
    "    l1_accuracies = []\n",
    "    l2_accuracies = []\n",
    "    for k in k_values:\n",
    "        l1_correct = 0\n",
    "        l2_correct = 0\n",
    "        total = 0\n",
    "        for v in tqdm(validation):\n",
    "            v_img = v[0]\n",
    "            v_label = v[1]\n",
    "            l1_scores = []\n",
    "            l2_scores = []\n",
    "            for t in train:\n",
    "                t_img = t[0]\n",
    "                t_label = t[1]\n",
    "                # L1 distance\n",
    "                l1_dist = np.sum(np.abs(t_img - v_img))\n",
    "                l1_scores.append((l1_dist, t_label))\n",
    "                # L2 distance\n",
    "                l2_dist = np.sqrt(np.sum((t_img - v_img) ** 2))\n",
    "                l2_scores.append((l2_dist, t_label))\n",
    "            sorted_l1_scores = sorted(l1_scores, key=lambda x: x[0])[:k]\n",
    "            l1_neighbors = [s[1] for s in sorted_l1_scores]\n",
    "            l1_prediction = max(set(l1_neighbors), key=l1_neighbors.count)\n",
    "\n",
    "            sorted_l2_scores = sorted(l2_scores, key=lambda x: x[0])[:k]\n",
    "            l2_neighbors = [s[1] for s in sorted_l2_scores]\n",
    "            l2_prediction = max(set(l2_neighbors), key=l2_neighbors.count)\n",
    "            if l1_prediction == v_label:\n",
    "                l1_correct += 1\n",
    "            if l2_prediction == v_label:\n",
    "                l2_correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "        l1_accuracy = l1_correct / total\n",
    "        l1_accuracies.append(l1_accuracy)\n",
    "\n",
    "        l2_accuracy = l2_correct / total\n",
    "        l2_accuracies.append(l2_accuracy)\n",
    "\n",
    "        print(\"Fold {}, k = {}, L1 accuracy = {:.2f}%, L2 accuracy = {:.2f}%\".format(i, k, l1_accuracy * 100, l2_accuracy * 100))\n",
    "\n",
    "    min_l1_accuracy = min(l1_accuracies)\n",
    "    max_l1_accuracy = max(l1_accuracies)\n",
    "    midpoint_l1_accuracy = (min_l1_accuracy + max_l1_accuracy) / 2\n",
    "    midpoint_l1_accuracies.append(midpoint_l1_accuracy)\n",
    "\n",
    "    min_l2_accuracy = min(l2_accuracies)\n",
    "    max_l2_accuracy = max(l2_accuracies)\n",
    "    midpoint_l2_accuracy = (min_l2_accuracy + max_l2_accuracy) / 2\n",
    "    midpoint_l2_accuracies.append(midpoint_l2_accuracy)\n",
    "\n",
    "    print(\"Midpoint L1 accuracy for Fold {} = {:.2f}%, Midpoint L2 accuracy for Fold {} = {:.2f}%\".format(i, midpoint_l1_accuracy * 100, i, midpoint_l2_accuracy * 100))\n",
    "\n",
    "plt.plot(k_values, midpoint_l1_accuracies, label='L1 distance')\n",
    "plt.plot(k_values, midpoint_l2_accuracies, label='L2 distance')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Midpoint accuracy')\n",
    "plt.title('KNN performance on CIFAR-10')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr_a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
